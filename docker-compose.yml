networks:
  chu_network:
    driver: bridge
  proxy:
    external: true   # réseau Traefik (uniquement pour chuweb/adminer)

volumes:
  pgdata:
  static_volume:
  media_volume:

services:
  chuDB:
    image: postgis/postgis:16-3.4
    restart: unless-stopped
    environment:
      POSTGRES_DB: ${DATABASE_NAME}
      POSTGRES_USER: ${DATABASE_USER}
      POSTGRES_PASSWORD: ${DATABASE_PASSWORD}
      PG_DATA: /data
    volumes:
      - pgdata:/var/lib/postgresql/data
    networks: [chu_network]   # ← plus de proxy ici
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U $$POSTGRES_USER -d $$POSTGRES_DB || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 10

  redis:
    image: redis:7
    restart: unless-stopped
    command: ["redis-server", "--appendonly", "yes", "--appendfsync", "everysec", "--save", "900 1"]
    networks: [chu_network]   # ← plus de proxy ici
    healthcheck:
      test: ["CMD-SHELL", "redis-cli -h 127.0.0.1 ping | grep PONG >/dev/null 2>&1 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 10

  chuweb:
    build:
      context: .
      dockerfile: Dockerfile
    command: >
      gunicorn smitci.wsgi:application
      --bind 0.0.0.0:8000
      --workers 2 --threads 2
      --timeout 60
      --log-level warning
    env_file: [.env]
    environment:
      - RUN_MIGRATIONS=1
      - RUN_COLLECTSTATIC=1
      - DJANGO_LOG_DIR=/chu-app/smitci/logs
      - USE_FILE_LOGS=1
    volumes:
      - .:/chu-app
      - static_volume:/chu-app/static
      - media_volume:/chu-app/media
    depends_on:
      chuDB:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped
    networks: [chu_network, proxy]
    healthcheck:
      test: ["CMD-SHELL", "python - <<'PY'\nimport urllib.request,sys\ntry:\n  urllib.request.urlopen('http://127.0.0.1:8000/healthz', timeout=2)\n  sys.exit(0)\nexcept Exception:\n  sys.exit(1)\nPY"]
      interval: 10s
      timeout: 3s
      retries: 12
      start_period: 40s
    labels:
      - traefik.enable=true
      - traefik.docker.network=proxy
      # Router HTTPS
      - traefik.http.routers.chu.rule=Host(`afriqconsulting.store`)
      - traefik.http.routers.chu.entrypoints=websecure
      - traefik.http.routers.chu.tls.certresolver=lets
      # Service (port interne)
      - traefik.http.services.chu.loadbalancer.server.port=8000
      - traefik.http.services.chu.loadbalancer.server.scheme=http
      # Middlewares (doivent exister côté Traefik)
      - traefik.http.routers.chu.middlewares=sec-headers@docker,compress@docker,ratelimit@docker

  celeryworker:
    build:
      context: .
      dockerfile: Dockerfile
    command: >
      celery -A chu worker
      --loglevel=warning
      --concurrency=1 --autoscale=2,1
      --prefetch-multiplier=1 -Ofair
      --max-tasks-per-child=100
      --without-gossip --without-mingle
    env_file: [.env]
    volumes:
      - .:/chu-app
    depends_on:
      chuDB:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped
    networks: [chu_network]

  celerybeat:
    build:
      context: .
      dockerfile: Dockerfile
    command: >
      celery -A chu beat
      --loglevel=warning
      --scheduler django_celery_beat.schedulers:DatabaseScheduler
    env_file: [.env]
    volumes:
      - .:/chu-app
    depends_on:
      chuDB:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped
    networks: [chu_network]

  chuadminer:
    profiles: ["admin"]   # lancer au besoin
    image: adminer
    restart: unless-stopped
    environment:
      ADMINER_DEFAULT_SERVER: chuDB
    depends_on:
      chuDB:
        condition: service_healthy
    networks: [chu_network, proxy]
    labels:
      - traefik.enable=true
      - traefik.docker.network=proxy
      - traefik.http.routers.chuadminer.rule=Host(`adminer.chu.com`)
      - traefik.http.routers.chuadminer.entrypoints=websecure
      - traefik.http.routers.chuadminer.tls.certresolver=lets
      - traefik.http.services.chuadminer.loadbalancer.server.port=8080
      - traefik.http.services.chuadminer.loadbalancer.server.scheme=http
      - traefik.http.routers.chuadminer.middlewares=traefik-auth@docker,sec-headers@docker,compress@docker,ratelimit@docker
#networks:
#  chu_network:
#    driver: bridge
#
#volumes:
#  pgdata:
#  static_volume:
#  media_volume:
#  logs_volume:
#
#services:
#  chuDB:
#    image: postgis/postgis:16-3.4
#    restart: always
#    environment:
#      POSTGRES_DB: ${DATABASE_NAME}
#      POSTGRES_USER: ${DATABASE_USER}
#      POSTGRES_PASSWORD: ${DATABASE_PASSWORD}
#      PG_DATA: /data
#    volumes:
#      - pgdata:/var/lib/postgresql/data
#    networks: [chu_network]
#    healthcheck:
#      test: ["CMD-SHELL", "pg_isready -U ${DATABASE_USER} -d ${DATABASE_NAME}"]
#      interval: 10s
#      timeout: 5s
#      retries: 10
#    # Limites (compatibles docker compose classique)
#    cpus: "1.0"
#    mem_limit: "1536m"
#
#  redis:
#    image: redis:7
#    container_name: chu_redis
#    restart: always
#    ports:
#      - "6388:6379"
#    networks: [chu_network]
#    healthcheck:
#      test: ["CMD", "redis-cli", "ping"]
#      interval: 10s
#      timeout: 5s
#      retries: 10
#    cpus: "0.20"
#    mem_limit: "256m"
#
#  chuweb:
#    build:
#      context: .
#      dockerfile: Dockerfile
#    # Réduit le coût Gunicorn (2 workers / 2 threads)
#    command: >
#      gunicorn chu.wsgi:application
#      --bind 0.0.0.0:8000
#      --workers 2 --threads 2
#      --timeout 60
#      --log-level warning
#    ports:
#      - "1909:8000"
#    volumes:
#      - .:/chu-app
#      - static_volume:/chu-app/static
#      - media_volume:/chu-app/media
#      - logs_volume:/var/log/app
#    env_file: [.env]
#    restart: always
#    depends_on:
#      chuDB:
#        condition: service_healthy
#      redis:
#        condition: service_healthy
#    networks: [chu_network]
#    cpus: "0.80"
#    mem_limit: "2024m"
#
#  celeryworker:
#    build:
#      context: .
#      dockerfile: Dockerfile
#    container_name: chu_celery_worker
#    command: >
#      celery -A chu worker
#      --loglevel=warning
#      --concurrency=1 --autoscale=2,1
#      --prefetch-multiplier=1 -Ofair
#      --max-tasks-per-child=100
#      --without-gossip --without-mingle
#    volumes:
#      - .:/chu-app
#    env_file: [.env]
#    restart: always
#    depends_on:
#      chuDB:
#        condition: service_healthy
#      redis:
#        condition: service_healthy
#    networks: [chu_network]
#    cpus: "0.60"
#    mem_limit: "768m"
#
#  celerybeat:
#    build:
#      context: .
#      dockerfile: Dockerfile
#    container_name: chu_celery_beat
#    command: >
#      celery -A chu beat
#      --loglevel=warning
#      --scheduler django_celery_beat.schedulers:DatabaseScheduler
#    volumes:
#      - .:/chu-app
#    env_file: [.env]
#    restart: always
#    depends_on:
#      chuDB:
#        condition: service_healthy
#      redis:
#        condition: service_healthy
#    networks: [chu_network]
#    cpus: "0.30"
#    mem_limit: "512m"
#
#  chuadminer:
#    image: adminer
#    restart: always
#    ports:
#      - "1910:8080"
#    environment:
#      ADMINER_DEFAULT_SERVER: chuDB
#    depends_on:
#      chuDB:
#        condition: service_healthy
#    networks: [chu_network]
#    cpus: "0.10"
#    mem_limit: "128m"
#
